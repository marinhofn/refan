#!/usr/bin/env python3
"""
DemonstraÃ§Ã£o focada na anÃ¡lise de dados com AMBAS classificaÃ§Ãµes (Purity + LLM)
Interface especÃ­fica para trabalhar apenas com commits jÃ¡ classificados por ambos sistemas.
"""

import sys
from pathlib import Path

# Configurar paths para imports funcionarem quando executado diretamente
if __name__ == "__main__":
    # Adicionar o diretÃ³rio raiz do projeto ao path
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))


import os
import sys
from datetime import datetime
from src.handlers.llm_visualization_handler import LLMVisualizationHandler
from analyze_dual_classifications import DualClassificationAnalyzer

def show_dual_classification_status():
    """Mostra o status dos dados com ambas classificaÃ§Ãµes."""
    
    print("ğŸ“Š Status dos Dados com Ambas ClassificaÃ§Ãµes")
    print("=" * 50)
    
    analyzer = DualClassificationAnalyzer()
    dual_data = analyzer.extract_dual_classified_data()
    
    if dual_data is not None and len(dual_data) > 0:
        print(f"\nâœ… Dados disponÃ­veis: {len(dual_data)} commits")
        
        # Mostrar estatÃ­sticas detalhadas
        print(f"\nğŸ“ˆ DistribuiÃ§Ã£o Detalhada:")
        
        # Por Purity
        purity_counts = dual_data['purity_analysis'].value_counts()
        print(f"\nğŸ” ClassificaÃ§Ã£o Purity:")
        for purity, count in purity_counts.items():
            percentage = count / len(dual_data) * 100
            print(f"   {purity:6}: {count:2} commits ({percentage:5.1f}%)")
        
        # Por LLM
        llm_counts = dual_data['llm_analysis'].value_counts()
        print(f"\nğŸ¤– ClassificaÃ§Ã£o LLM:")
        for llm, count in llm_counts.items():
            percentage = count / len(dual_data) * 100
            print(f"   {llm:6}: {count:2} commits ({percentage:5.1f}%)")
        
        # Acordos/Desacordos
        dual_data_copy = dual_data.copy()
        dual_data_copy['purity_norm'] = dual_data_copy['purity_analysis'].map({
            'TRUE': 'PURE', 'FALSE': 'FLOSS', 'NONE': 'UNKNOWN'
        })
        dual_data_copy['agreement'] = dual_data_copy['purity_norm'] == dual_data_copy['llm_analysis']
        
        agreements = dual_data_copy['agreement'].sum()
        disagreements = len(dual_data_copy) - agreements
        agreement_rate = agreements / len(dual_data_copy) * 100
        
        print(f"\nğŸ¯ Acordo/Desacordo:")
        print(f"   Acordos:     {agreements:2} commits ({agreement_rate:5.1f}%)")
        print(f"   Desacordos:  {disagreements:2} commits ({100-agreement_rate:5.1f}%)")
        
        return True
    else:
        print("\nâŒ Nenhum dado com ambas classificaÃ§Ãµes encontrado")
        print("\nğŸ’¡ Para gerar dados:")
        print("   1. Execute mais anÃ¡lises LLM: python run_llm_analysis.py")
        print("   2. Depois execute: python analyze_dual_classifications.py")
        return False

def main():
    """FunÃ§Ã£o principal para anÃ¡lise de dados com ambas classificaÃ§Ãµes."""
    
    print("ğŸ” ANÃLISE DE DADOS COM AMBAS CLASSIFICAÃ‡Ã•ES")
    print("=" * 50)
    
    # Verificar status dos dados
    has_data = show_dual_classification_status()
    
    if not has_data:
        return
    
    # Menu de opÃ§Ãµes
    while True:
        print(f"\nğŸ¯ OpÃ§Ãµes de AnÃ¡lise (Dados com Ambas ClassificaÃ§Ãµes):")
        print("1. ğŸ“Š Gerar novo CSV de comparaÃ§Ã£o")
        print("2. ğŸ“ˆ Criar visualizaÃ§Ãµes especÃ­ficas")
        print("3. ğŸ¨ Dashboard interativo completo")
        print("4. ğŸ“¦ Exportar pacote de anÃ¡lise")
        print("5. ğŸ“‹ RelatÃ³rio detalhado de desacordos")
        print("6. ğŸ”„ Atualizar dados (re-extrair)")
        print("0. âŒ Sair")
        
        choice = input(f"\nEscolha uma opÃ§Ã£o (0-6): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ Saindo...")
            break
            
        elif choice == "1":
            print("\nğŸ“Š Gerando novo CSV de comparaÃ§Ã£o...")
            analyzer = DualClassificationAnalyzer()
            dual_data = analyzer.extract_dual_classified_data()
            if dual_data is not None:
                csv_file = analyzer.create_comparison_csv(dual_data, include_repository_info=True)
                stats = analyzer.analyze_agreements(dual_data)
                report_file = analyzer.save_analysis_report(stats, csv_file)
                print(f"\nâœ… Arquivos gerados:")
                print(f"   ğŸ“„ CSV: {csv_file}")
                print(f"   ğŸ“Š RelatÃ³rio: {report_file}")
                
        elif choice == "2":
            print("\nğŸ“ˆ Criando visualizaÃ§Ãµes especÃ­ficas...")
            handler = LLMVisualizationHandler()
            try:
                df = handler.load_comparison_data(prefer_dual_classification=True)
                print(f"âœ… Dados carregados: {len(df)} comparaÃ§Ãµes")
                
                # Criar visualizaÃ§Ãµes individuais
                timestamp = datetime.now().strftime("%H-%M-%S")
                
                # Agreement overview
                agreement_fig = handler.create_agreement_overview(df)
                agreement_path = f"dual_agreement_chart_{timestamp}.html"
                agreement_fig.write_html(agreement_path)
                print(f"   ğŸ“Š GrÃ¡fico de acordo: {agreement_path}")
                
                # Confusion matrix
                confusion_fig = handler.create_confusion_matrix(df)
                confusion_path = f"dual_confusion_matrix_{timestamp}.html"
                confusion_fig.write_html(confusion_path)
                print(f"   ğŸ”„ Matriz de confusÃ£o: {confusion_path}")
                
                # Repository analysis
                repo_fig = handler.create_repository_analysis(df)
                repo_path = f"dual_repository_analysis_{timestamp}.html"
                repo_fig.write_html(repo_path)
                print(f"   ğŸ›ï¸ AnÃ¡lise por repositÃ³rio: {repo_path}")
                
                print(f"\nâœ… VisualizaÃ§Ãµes criadas com sucesso!")
                
            except Exception as e:
                print(f"âŒ Erro: {e}")
                
        elif choice == "3":
            print("\nğŸ¨ Criando dashboard interativo completo...")
            handler = LLMVisualizationHandler()
            try:
                dashboard_path = handler.create_comprehensive_dashboard()
                if dashboard_path:
                    print(f"âœ… Dashboard criado: {dashboard_path}")
                    
                    # Tentar abrir no navegador
                    try:
                        import webbrowser
                        webbrowser.open(f"file://{os.path.abspath(dashboard_path)}")
                        print("ğŸŒ Dashboard aberto no navegador")
                    except:
                        print("ğŸ’¡ Abra o arquivo HTML manualmente no navegador")
                        
            except Exception as e:
                print(f"âŒ Erro: {e}")
                
        elif choice == "4":
            print("\nğŸ“¦ Criando pacote completo de anÃ¡lise...")
            handler = LLMVisualizationHandler()
            try:
                package_path = handler.create_export_package()
                if package_path:
                    print(f"âœ… Pacote criado: {package_path}")
                    print(f"ğŸ“ ContÃ©m dados, visualizaÃ§Ãµes e relatÃ³rios completos")
                    
            except Exception as e:
                print(f"âŒ Erro: {e}")
                
        elif choice == "5":
            print("\nğŸ“‹ Analisando padrÃµes de desacordo...")
            handler = LLMVisualizationHandler()
            try:
                df = handler.load_comparison_data(prefer_dual_classification=True)
                
                # AnÃ¡lise detalhada de desacordos
                disagreements = df[~df['agreement']]
                
                print(f"\nğŸ” AnÃ¡lise de Desacordos:")
                print(f"   Total de desacordos: {len(disagreements)}")
                print(f"   Taxa de desacordo: {len(disagreements)/len(df)*100:.1f}%")
                
                print(f"\nğŸ“Š PadrÃµes de Desacordo:")
                disagreement_patterns = disagreements.groupby(['purity_classification', 'llm_classification']).size()
                for (purity, llm), count in disagreement_patterns.items():
                    print(f"   Purity:{purity:7} â†’ LLM:{llm:5} : {count} casos")
                
                # Salvar detalhes dos desacordos
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                disagreements_file = f"disagreements_analysis_{timestamp}.csv"
                disagreements.to_csv(disagreements_file, index=False)
                print(f"\nâœ… Detalhes salvos em: {disagreements_file}")
                
            except Exception as e:
                print(f"âŒ Erro: {e}")
                
        elif choice == "6":
            print("\nğŸ”„ Atualizando dados...")
            show_dual_classification_status()
            
        else:
            print("âŒ OpÃ§Ã£o invÃ¡lida")

if __name__ == "__main__":
    main()
